# XGBoost Cancer Mortality Prediction and Survival Analysis

This project develops and evaluates an XGBoost machine learning model to predict death attributable to cancer using [mention data source briefly, e.g., SEER data]. It also includes scripts for data processing, feature engineering (including interaction terms), hyperparameter tuning, and generating a Kaplan-Meier survival plot stratified by the model's predicted risk.

## Project Structure

```
├── predictive_dataset.csv        # Original raw dataset (example or placeholder)
├── data_cleaning.py              # Script for initial data cleaning
├── encode_categorical.py         # Script for one-hot encoding
├── predictive_dataset_encoded.csv # Encoded dataset (example or placeholder)
├── split_data.py                 # Script to split data into train/val/test sets
├── create_interactions.py        # Script to generate interaction features
├── train_evaluate_xgboost.py     # Script for feature selection, tuning, training, and evaluation
├── venv/Scripts/generate_km_plots.py # Script to load model, predict, and generate KM plot
├── requirements.txt              # Python package dependencies
├── .gitignore                    # Specifies intentionally untracked files
└── README.md                     # This file
```

*(Note: Generated data folders like `split_data/`, `interaction_data/`, `model_results/`, and `report/` are excluded via `.gitignore` but are created by the scripts.)*

## Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/orthopendar/xgboost-cancer-prediction.git
    cd xgboost-cancer-prediction
    ```
2.  **Create and activate a virtual environment:** (Recommended)
    *   Using `venv`:
        ```bash
        python -m venv venv
        # On Windows (PowerShell)
        .\venv\Scripts\Activate.ps1
        # On macOS/Linux
        # source venv/bin/activate
        ```
    *   Or using `conda`:
        ```bash
        # conda create --name xgb_cancer python=3.9 # Or your preferred version
        # conda activate xgb_cancer
        ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Place Data:** Ensure the initial raw dataset (`predictive_dataset.csv`) is present in the root directory. *(If using a different source or name, update the path variables within the scripts accordingly).*

## Usage

The scripts are designed to be run sequentially:

1.  **Data Cleaning:**
    ```bash
    python data_cleaning.py
    ```
    *(Modify this script based on your specific initial cleaning needs)*
2.  **Encode Categorical Features:**
    ```bash
    python encode_categorical.py
    ```
    *(Creates `predictive_dataset_encoded.csv`)*
3.  **Split Data:**
    ```bash
    python split_data.py
    ```
    *(Creates train/val/test CSV files in `split_data/`)*
4.  **Generate Interaction Features:**
    ```bash
    python create_interactions.py
    ```
    *(Creates train/val/test CSV files with interactions in `interaction_data/`)*
5.  **Train, Evaluate, and Tune Model:**
    ```bash
    python train_evaluate_xgboost.py
    ```
    *(Saves final model and results to `model_results/`)*
6.  **Generate Evaluation Plots:**
    ```bash
    python generate_evaluation_plots.py
    ```
    *(Saves various plots like ROC, PR, Confusion Matrix, Feature Importance, SHAP summary, Calibration to `report/`)*
7.  **Generate Kaplan-Meier Plot:**
    ```bash
    python ./venv/Scripts/generate_km_plots.py
    ```
    *(Saves plot to `report/km_stratified_by_prediction.png`)*

*(Note: Ensure path variables within the Python scripts correctly point to your data, model, and output locations if you deviate from the default structure.)*

## Results Summary

The final XGBoost model achieved:
*   Test Set Accuracy: 0.9758
*   Test Set ROC AUC: 0.9953

A Kaplan-Meier analysis demonstrated significant stratification of survival based on the model's predicted risk probabilities (see `report/km_stratified_by_prediction.png` generated by the script).

## Contributing

[Optional: Add guidelines for contributing if this is an open project.]

## License

[Optional: Add a license file (e.g., MIT, Apache 2.0) and reference it here.] 